{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'TQK6RH09SNTN6E2W',\n",
       "  'HostId': 'nqwsDOFpEtuu5hVMSD5eXCcriJY2v174OvNZSFXkHtETVK5snf4wHnLQq/W5qBl6e8kd3pdnzz0=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'nqwsDOFpEtuu5hVMSD5eXCcriJY2v174OvNZSFXkHtETVK5snf4wHnLQq/W5qBl6e8kd3pdnzz0=',\n",
       "   'x-amz-request-id': 'TQK6RH09SNTN6E2W',\n",
       "   'date': 'Thu, 25 May 2023 04:40:53 GMT',\n",
       "   'location': '/test-bucket-yingzi',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': '/test-bucket-yingzi'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.create_bucket(Bucket='test-bucket-yingzi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create EMR Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\naws emr create-cluster     --name \"Spark Cluster\"     --release-label \"emr-6.2.0\"     --applications Name=Hadoop Name=Hive Name=JupyterEnterpriseGateway Name=JupyterHub Name=Livy Name=Pig Name=Spark Name=Tez     --instance-type m5.xlarge     --instance-count 5     --use-default-roles     --region us-east-1     --ec2-attributes \\'{\"KeyName\": \"vockey\"}\\'     --configurations \\'[{\"Classification\": \"jupyter-s3-conf\", \"Properties\": {\"s3.persistence.enabled\": \"true\", \"s3.persistence.bucket\": \"test-bucket-yingzi\"}}]\\'\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "aws emr create-cluster \\\n",
    "    --name \"Spark Cluster\" \\\n",
    "    --release-label \"emr-6.2.0\" \\\n",
    "    --applications Name=Hadoop Name=Hive Name=JupyterEnterpriseGateway Name=JupyterHub Name=Livy Name=Pig Name=Spark Name=Tez \\\n",
    "    --instance-type m5.xlarge \\\n",
    "    --instance-count 5 \\\n",
    "    --use-default-roles \\\n",
    "    --region us-east-1 \\\n",
    "    --ec2-attributes '{\"KeyName\": \"vockey\"}' \\\n",
    "    --configurations '[{\"Classification\": \"jupyter-s3-conf\", \"Properties\": {\"s3.persistence.enabled\": \"true\", \"s3.persistence.bucket\": \"test-bucket-yingzi\"}}]'\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssh -i /Users/axyz1220/Downloads/macs30123/A3/labsuser.pem -NL 9443:localhost:9443 hadoop@ec2-54-224-199-218.compute-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://localhost:9443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export RDS snapshot and Store the data in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = boto3.client('rds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create db instance\n",
    "response = rds.create_db_instance(\n",
    "    DBInstanceIdentifier='relational-db2',\n",
    "    DBName='reddit_scrapes',\n",
    "    MasterUsername='username',\n",
    "    MasterUserPassword='password',\n",
    "    DBInstanceClass='db.t2.micro',\n",
    "    Engine='mysql',\n",
    "    AllocatedStorage=5\n",
    ")\n",
    "# Wait until DB is available to continue\n",
    "rds.get_waiter('db_instance_available') \\\n",
    "   .wait(DBInstanceIdentifier='relational-db2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relational-db2 is available at relational-db2.csndcbhvlggl.us-east-1.rds.amazonaws.com on Port 3306\n"
     ]
    }
   ],
   "source": [
    "# Describe where DB is available and on what port\n",
    "db = rds.describe_db_instances()['DBInstances'][1]\n",
    "ENDPOINT = db['Endpoint']['Address']\n",
    "PORT = db['Endpoint']['Port']\n",
    "DBID = db['DBInstanceIdentifier']\n",
    "\n",
    "print(DBID,\n",
    "      \"is available at\", ENDPOINT,\n",
    "      \"on Port\", PORT,\n",
    "     )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permissions already adjusted.\n"
     ]
    }
   ],
   "source": [
    "# Get Name of Security Group\n",
    "SGNAME = db['VpcSecurityGroups'][0]['VpcSecurityGroupId']\n",
    "\n",
    "# Adjust Permissions for that security group so that we can access it on Port 3306\n",
    "# If already SG is already adjusted, print this out\n",
    "try:\n",
    "    ec2 = boto3.client('ec2')\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "            GroupId=SGNAME,\n",
    "            IpPermissions=[\n",
    "                {'IpProtocol': 'tcp',\n",
    "                 'FromPort': PORT,\n",
    "                 'ToPort': PORT,\n",
    "                 'IpRanges': [{'CidrIp': '0.0.0.0/0'}]}\n",
    "            ]\n",
    "    )\n",
    "except ec2.exceptions.ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == 'InvalidPermission.Duplicate':\n",
    "        print(\"Permissions already adjusted.\")\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn =  mysql.connector.connect(host=ENDPOINT,\n",
    "                                user=\"username\",\n",
    "                                passwd=\"password\", \n",
    "                                port=PORT, \n",
    "                                database='reddit_scrapes')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('comments',), ('posts',)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SHOW TABLES\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20889\n",
      "('Firearms', None, 33, 'The founders were men committing treason against the ruling state.\\n\\nWhy would they ever turn around and say only the state can dictate who has what weapons and for what purpose\\n\\nFn regarded af', 'https://www.reddit.com/r/Firearms/comments/13ihyp5/vox_a_new_supreme_court_case_seeks_to_legalize/', 'jk9wvum')\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT * FROM comments\")\n",
    "rows = cur.fetchall()\n",
    "print(len(list(rows)))\n",
    "print(list(rows)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-12.0.0-cp310-cp310-macosx_10_14_x86_64.whl (24.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /Users/axyz1220/anaconda3/lib/python3.10/site-packages (from pyarrow) (1.23.5)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-12.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [i[0] for i in cur.description]    \n",
    "df_comments = pd.DataFrame(rows, columns=column_names)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df_comments)\n",
    "\n",
    "# Define the output Parquet file path\n",
    "output_file = \"comments.parquet\"\n",
    "\n",
    "# Write the PyArrow Table to Parquet file\n",
    "pq.write_table(table, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM posts\")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "column_names = [i[0] for i in cur.description]    \n",
    "df_posts = pd.DataFrame(rows, columns=column_names)  \n",
    "\n",
    "table = pa.Table.from_pandas(df_posts)\n",
    "\n",
    "# Define the output Parquet file path\n",
    "output_file = \"posts.parquet\"\n",
    "\n",
    "# Write the PyArrow Table to Parquet file\n",
    "pq.write_table(table, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_pd(df, body, valence, moral, frac):\n",
    "    if body:\n",
    "        col2 = 'body_valence'\n",
    "    else:\n",
    "        col2 = 'title_valence'\n",
    "    \n",
    "    if moral == 'high':\n",
    "        mc = 1\n",
    "    else:\n",
    "        mc = 0\n",
    "     \n",
    "    df_select = df.filter((col('moral_conviction')==mc) & (col(col2)==valence))\n",
    "    df_select = df_select.filter(col('engagement') > 0)\n",
    "    df_sample = df_select.sample(fraction=frac)\n",
    "    df_sample = df_sample.withColumn('log_engagement', log(col('engagement')))\n",
    "\n",
    "    pd_sample = df_sample.toPandas()\n",
    "    return pd_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg_plot(pd, model, body, valence, moral, content):\n",
    "    coeff = model.coefficients[0]\n",
    "    intercept = model.intercept\n",
    "    \n",
    "    if body:\n",
    "        column = 'abs_body_intensity'\n",
    "    else:\n",
    "        column = 'abs_title_intensity'\n",
    "        \n",
    "    \n",
    "    if valence == 'pos':\n",
    "        label1 = 'Positive'\n",
    "    else:\n",
    "        label1 = 'Negative'\n",
    "        \n",
    "    if moral == 'high':\n",
    "        label2 = 'High'\n",
    "    else:\n",
    "        label2 = 'Low'\n",
    "    \n",
    "    pred = pd[column] * coeff + intercept\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    plt.scatter(pd[column], pd['log_engagement'])\n",
    "    plt.plot(pd[column], pred, color='red', label='Linear Regression')\n",
    "    \n",
    "    plt.title(f'Linear Rregression for {content} with {label2}-level Moral Conviction',\n",
    "             fontsize = 10)\n",
    "    plt.xlabel(f'{label1} Absolute Intensity')\n",
    "    plt.ylabel('Log-transformed Engagement')\n",
    "    plt.legend()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_body_neg_high_pd = df_to_pd(df_posts, True, 'neg', 'high', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = linear_reg_plot(posts_body_neg_high_pd, lr_body_neg_high, True, 'neg', 'high', \"Posts' Body\")\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_body_pos_low_pd = df_to_pd(df_posts, True, 'pos', 'low', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = linear_reg_plot(posts_body_pos_low_pd, lr_body_pos_low, True, 'pos', 'low', \"Posts' Body\")\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate posts\n",
    "\n",
    "data_posts = data_posts.dropDuplicates(['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate comments\n",
    "\n",
    "data_comments = data_comments.dropDuplicates(['comment_body'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f759ffef1a6238f0cc7d082b1d1c10faeac2a7e5e5cd247bc6e13d55eb9f4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
