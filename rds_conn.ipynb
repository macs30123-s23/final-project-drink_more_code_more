{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_lambda = boto3.client('lambda')\n",
    "iam = boto3.client('iam')\n",
    "role = iam.get_role(RoleName='LabRole')\n",
    "rds = boto3.client('rds')\n",
    "sfn = boto3.client('stepfunctions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDS\n",
    "response = rds.create_db_instance(\n",
    "    DBInstanceIdentifier='relational-db',\n",
    "    DBName='reddit_scrapes',\n",
    "    MasterUsername='username',\n",
    "    MasterUserPassword='password',\n",
    "    DBInstanceClass='db.t2.micro',\n",
    "    Engine='mysql',\n",
    "    AllocatedStorage=5\n",
    ")\n",
    "\n",
    "# Wait until DB is available to continue\n",
    "rds.get_waiter('db_instance_available') \\\n",
    "   .wait(DBInstanceIdentifier='relational-db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relational-db is available at relational-db.c2j1y7tdjd25.us-east-1.rds.amazonaws.com on Port 3306\n"
     ]
    }
   ],
   "source": [
    "# Describe where DB is available and on what port\n",
    "db = rds.describe_db_instances()['DBInstances'][0]\n",
    "ENDPOINT = db['Endpoint']['Address']\n",
    "PORT = db['Endpoint']['Port']\n",
    "DBID = db['DBInstanceIdentifier']\n",
    "\n",
    "print(DBID,\n",
    "      \"is available at\", ENDPOINT,\n",
    "      \"on Port\", PORT,\n",
    "     ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permissions already adjusted.\n"
     ]
    }
   ],
   "source": [
    "# Get Name of Security Group\n",
    "SGNAME = db['VpcSecurityGroups'][0]['VpcSecurityGroupId']\n",
    "\n",
    "# Adjust Permissions for that security group so that we can access it on Port 3306\n",
    "# If already SG is already adjusted, print this out\n",
    "try:\n",
    "    ec2 = boto3.client('ec2')\n",
    "    data = ec2.authorize_security_group_ingress(\n",
    "            GroupId=SGNAME,\n",
    "            IpPermissions=[\n",
    "                {'IpProtocol': 'tcp',\n",
    "                 'FromPort': PORT,\n",
    "                 'ToPort': PORT,\n",
    "                 'IpRanges': [{'CidrIp': '0.0.0.0/0'}]}\n",
    "            ]\n",
    "    )\n",
    "except ec2.exceptions.ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == 'InvalidPermission.Duplicate':\n",
    "        print(\"Permissions already adjusted.\")\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda function 1 to parallelize post scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lambda function 1\n",
    "with open('final-deploy.zip', 'rb') as f:\n",
    "    lambda_zip = f.read()\n",
    "\n",
    "try:\n",
    "    # If function hasn't yet been created, create it\n",
    "    response = aws_lambda.create_function(\n",
    "        FunctionName='lambda1',\n",
    "        Runtime='python3.9',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='lambda1.lambda_handler',\n",
    "        Code=dict(ZipFile=lambda_zip),\n",
    "        Timeout=300\n",
    "    )\n",
    "except aws_lambda.exceptions.ResourceConflictException:\n",
    "    # If function already exists, update it based on zip\n",
    "    # file contents\n",
    "    response = aws_lambda.update_function_code(\n",
    "    FunctionName='lambda1',\n",
    "    ZipFile=lambda_zip\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_arn = [f['FunctionArn'] for f in aws_lambda.list_functions()['Functions']\n",
    "            if f['FunctionName'] == 'lambda1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:lambda:us-east-1:254224570814:function:lambda1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_def(lambda_arn):\n",
    "    definition = {\n",
    "        \"Comment\": \"My State Machine\",\n",
    "        \"StartAt\": \"Map\",\n",
    "        \"States\": {\n",
    "            \"Map\": {\n",
    "                \"Type\": \"Map\",\n",
    "                \"End\": True,\n",
    "                \"Iterator\": {\n",
    "                    \"StartAt\": \"Lambda Invoke\",\n",
    "                    \"States\": {\n",
    "                        \"Lambda Invoke\": {\n",
    "                            \"Type\": \"Task\",\n",
    "                            \"Resource\": \"arn:aws:states:::lambda:invoke\",\n",
    "                            \"OutputPath\": \"$.Payload\",\n",
    "                            \"Parameters\": {\n",
    "                                \"Payload.$\": \"$\",\n",
    "                                \"FunctionName\": lambda_arn\n",
    "                            },\n",
    "                            \"Retry\": [\n",
    "                                {\n",
    "                                    \"ErrorEquals\": [\n",
    "                                        \"Lambda.ServiceException\",\n",
    "                                        \"Lambda.AWSLambdaException\",\n",
    "                                        \"Lambda.SdkClientException\",\n",
    "                                        \"Lambda.TooManyRequestsException\",\n",
    "                                        \"States.TaskFailed\"\n",
    "                                    ],\n",
    "                                    \"IntervalSeconds\": 2,\n",
    "                                    \"MaxAttempts\": 6,\n",
    "                                    \"BackoffRate\": 2\n",
    "                                }\n",
    "                            ],\n",
    "                            \"End\": True\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_def = make_def(lambda_arn)\n",
    "# Create state machine\n",
    "try:\n",
    "    response = sfn.create_state_machine(\n",
    "        name='post_scraping',\n",
    "        definition=json.dumps(sf_def),\n",
    "        roleArn=role['Role']['Arn'],\n",
    "        type='EXPRESS'\n",
    "    )\n",
    "except sfn.exceptions.StateMachineAlreadyExists:\n",
    "    response = sfn.list_state_machines()\n",
    "    state_machine_arn = [sm['stateMachineArn'] \n",
    "                         for sm in response['stateMachines'] \n",
    "                         if sm['name'] == 'post_scraping'][0]\n",
    "    response = sfn.update_state_machine(\n",
    "        stateMachineArn=state_machine_arn,\n",
    "        definition=json.dumps(sf_def),\n",
    "        roleArn=role['Role']['Arn']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stateMachines': [{'stateMachineArn': 'arn:aws:states:us-east-1:254224570814:stateMachine:comment_scraping',\n",
       "   'name': 'comment_scraping',\n",
       "   'type': 'EXPRESS',\n",
       "   'creationDate': datetime.datetime(2023, 5, 25, 13, 36, 55, 639000, tzinfo=tzlocal())},\n",
       "  {'stateMachineArn': 'arn:aws:states:us-east-1:254224570814:stateMachine:post_scraping',\n",
       "   'name': 'post_scraping',\n",
       "   'type': 'EXPRESS',\n",
       "   'creationDate': datetime.datetime(2023, 5, 25, 10, 12, 8, 607000, tzinfo=tzlocal())}],\n",
       " 'ResponseMetadata': {'RequestId': '8f72e275-b777-4064-acfc-a5d41df22168',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '8f72e275-b777-4064-acfc-a5d41df22168',\n",
       "   'date': 'Thu, 25 May 2023 22:44:57 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '343'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = sfn.list_state_machines()\n",
    "# Get arn for Step Function state machine\n",
    "state_machine_arn = [sm['stateMachineArn'] \n",
    "                     for sm in response['stateMachines'] \n",
    "                     if sm['name'] == 'post_scraping'][0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tables in RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = 'mysql+mysqlconnector://{}:{}@{}:{}/reddit_scrapes'.format('username',\n",
    "                                                                   'password',\n",
    "                                                                ENDPOINT, PORT)\n",
    "db = dataset.connect(db_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### posts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.util.ResultIter at 0x22683295160>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS posts (\n",
    "        subreddit VARCHAR(255),\n",
    "        id VARCHAR(255),\n",
    "        title TEXT,\n",
    "        score INTEGER,\n",
    "        url VARCHAR(255),\n",
    "        comms_num INTEGER,\n",
    "        body TEXT,\n",
    "        ups INTEGER\n",
    "    )\n",
    "\"\"\"\n",
    "db.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['posts']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_subreddits = ['firearms', 'gunpolitics', 'Abortiondebate', 'prolife', 'prochoice', 'Music', 'LetsTalkMusic', 'movies', 'MovieSuggestions']\n",
    "# For each of the subreddits, do the following using different lambda workers.\n",
    "batches = [{'subreddit': i} for i in lst_subreddits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subreddit': 'firearms'},\n",
       " {'subreddit': 'gunpolitics'},\n",
       " {'subreddit': 'Abortiondebate'},\n",
       " {'subreddit': 'prolife'},\n",
       " {'subreddit': 'prochoice'},\n",
       " {'subreddit': 'Music'},\n",
       " {'subreddit': 'LetsTalkMusic'},\n",
       " {'subreddit': 'movies'},\n",
       " {'subreddit': 'MovieSuggestions'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronous Execution\n",
    "response = sfn.start_sync_execution(\n",
    "    stateMachineArn=state_machine_arn,\n",
    "    name='sync_scrape',\n",
    "    input=json.dumps(batches)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3940"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DBInstance': {'DBInstanceIdentifier': 'relational-db',\n",
       "  'DBInstanceClass': 'db.t2.micro',\n",
       "  'Engine': 'mysql',\n",
       "  'DBInstanceStatus': 'rebooting',\n",
       "  'MasterUsername': 'username',\n",
       "  'DBName': 'reddit_scrapes',\n",
       "  'Endpoint': {'Address': 'relational-db.c2j1y7tdjd25.us-east-1.rds.amazonaws.com',\n",
       "   'Port': 3306,\n",
       "   'HostedZoneId': 'Z2R2ITUGPM61AM'},\n",
       "  'AllocatedStorage': 5,\n",
       "  'InstanceCreateTime': datetime.datetime(2023, 5, 25, 14, 21, 18, 81000, tzinfo=tzutc()),\n",
       "  'PreferredBackupWindow': '07:08-07:38',\n",
       "  'BackupRetentionPeriod': 1,\n",
       "  'DBSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-06defb149cb9e5d43',\n",
       "    'Status': 'active'}],\n",
       "  'DBParameterGroups': [{'DBParameterGroupName': 'default.mysql8.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'AvailabilityZone': 'us-east-1f',\n",
       "  'DBSubnetGroup': {'DBSubnetGroupName': 'default',\n",
       "   'DBSubnetGroupDescription': 'default',\n",
       "   'VpcId': 'vpc-038429464fd438924',\n",
       "   'SubnetGroupStatus': 'Complete',\n",
       "   'Subnets': [{'SubnetIdentifier': 'subnet-0e41ce1a6e9aa3d92',\n",
       "     'SubnetAvailabilityZone': {'Name': 'us-east-1a'},\n",
       "     'SubnetOutpost': {},\n",
       "     'SubnetStatus': 'Active'},\n",
       "    {'SubnetIdentifier': 'subnet-08d3c4d938513caf1',\n",
       "     'SubnetAvailabilityZone': {'Name': 'us-east-1b'},\n",
       "     'SubnetOutpost': {},\n",
       "     'SubnetStatus': 'Active'},\n",
       "    {'SubnetIdentifier': 'subnet-0967763329cac7e6b',\n",
       "     'SubnetAvailabilityZone': {'Name': 'us-east-1d'},\n",
       "     'SubnetOutpost': {},\n",
       "     'SubnetStatus': 'Active'},\n",
       "    {'SubnetIdentifier': 'subnet-020f63d80ac26d075',\n",
       "     'SubnetAvailabilityZone': {'Name': 'us-east-1c'},\n",
       "     'SubnetOutpost': {},\n",
       "     'SubnetStatus': 'Active'},\n",
       "    {'SubnetIdentifier': 'subnet-07673328d1d1b2be8',\n",
       "     'SubnetAvailabilityZone': {'Name': 'us-east-1e'},\n",
       "     'SubnetOutpost': {},\n",
       "     'SubnetStatus': 'Active'},\n",
       "    {'SubnetIdentifier': 'subnet-046c01c4d4cc6dec3',\n",
       "     'SubnetAvailabilityZone': {'Name': 'us-east-1f'},\n",
       "     'SubnetOutpost': {},\n",
       "     'SubnetStatus': 'Active'}]},\n",
       "  'PreferredMaintenanceWindow': 'wed:10:25-wed:10:55',\n",
       "  'PendingModifiedValues': {},\n",
       "  'LatestRestorableTime': datetime.datetime(2023, 5, 25, 22, 40, 1, tzinfo=tzutc()),\n",
       "  'MultiAZ': False,\n",
       "  'EngineVersion': '8.0.32',\n",
       "  'AutoMinorVersionUpgrade': True,\n",
       "  'ReadReplicaDBInstanceIdentifiers': [],\n",
       "  'LicenseModel': 'general-public-license',\n",
       "  'OptionGroupMemberships': [{'OptionGroupName': 'default:mysql-8-0',\n",
       "    'Status': 'in-sync'}],\n",
       "  'PubliclyAccessible': True,\n",
       "  'StorageType': 'gp2',\n",
       "  'DbInstancePort': 0,\n",
       "  'StorageEncrypted': False,\n",
       "  'DbiResourceId': 'db-MKJ4KOE5M72W6BG7ZBHKUCN5PQ',\n",
       "  'CACertificateIdentifier': 'rds-ca-2019',\n",
       "  'DomainMemberships': [],\n",
       "  'CopyTagsToSnapshot': False,\n",
       "  'MonitoringInterval': 0,\n",
       "  'DBInstanceArn': 'arn:aws:rds:us-east-1:254224570814:db:relational-db',\n",
       "  'IAMDatabaseAuthenticationEnabled': False,\n",
       "  'PerformanceInsightsEnabled': False,\n",
       "  'DeletionProtection': False,\n",
       "  'AssociatedRoles': [],\n",
       "  'TagList': [],\n",
       "  'CustomerOwnedIpEnabled': False,\n",
       "  'BackupTarget': 'region',\n",
       "  'NetworkType': 'IPV4',\n",
       "  'StorageThroughput': 0,\n",
       "  'CertificateDetails': {'CAIdentifier': 'rds-ca-2019',\n",
       "   'ValidTill': datetime.datetime(2024, 8, 22, 17, 8, 50, tzinfo=tzutc())}},\n",
       " 'ResponseMetadata': {'RequestId': '76cb5eb1-99aa-4eff-9b0b-a885808cc2bd',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '76cb5eb1-99aa-4eff-9b0b-a885808cc2bd',\n",
       "   'strict-transport-security': 'max-age=31536000',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '5580',\n",
       "   'date': 'Thu, 25 May 2023 22:47:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reboot RDS before the second scraping\n",
    "rds.reboot_db_instance(DBInstanceIdentifier='relational-db')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda function 2 to parallelize comment scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lambda function 2\n",
    "with open('final-deploy2.zip', 'rb') as f:\n",
    "    lambda_zip = f.read()\n",
    "\n",
    "try:\n",
    "    # If function hasn't yet been created, create it\n",
    "    response = aws_lambda.create_function(\n",
    "        FunctionName='lambda2',\n",
    "        Runtime='python3.9',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='lambda2.lambda_handler',\n",
    "        Code=dict(ZipFile=lambda_zip),\n",
    "        Timeout=600\n",
    "    )\n",
    "except aws_lambda.exceptions.ResourceConflictException:\n",
    "    # If function already exists, update it based on zip\n",
    "    # file contents\n",
    "    response = aws_lambda.update_function_code(\n",
    "    FunctionName='lambda2',\n",
    "    ZipFile=lambda_zip\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_arn2 = [f['FunctionArn'] for f in aws_lambda.list_functions()['Functions']\n",
    "            if f['FunctionName'] == 'lambda2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:lambda:us-east-1:254224570814:function:lambda2'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_arn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_def2 = make_def(lambda_arn2)\n",
    "# Create state machine\n",
    "try:\n",
    "    response2 = sfn.create_state_machine(\n",
    "        name='comment_scraping',\n",
    "        definition=json.dumps(sf_def2),\n",
    "        roleArn=role['Role']['Arn'],\n",
    "        type='EXPRESS'\n",
    "    )\n",
    "except sfn.exceptions.StateMachineAlreadyExists:\n",
    "    response2 = sfn.list_state_machines()\n",
    "    state_machine_arn = [sm['stateMachineArn'] \n",
    "                         for sm in response['stateMachines'] \n",
    "                         if sm['name'] == 'comment_scraping'][0]\n",
    "    response2 = sfn.update_state_machine(\n",
    "        stateMachineArn=state_machine_arn,\n",
    "        definition=json.dumps(sf_def2),\n",
    "        roleArn=role['Role']['Arn']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stateMachines': [{'stateMachineArn': 'arn:aws:states:us-east-1:254224570814:stateMachine:comment_scraping',\n",
       "   'name': 'comment_scraping',\n",
       "   'type': 'EXPRESS',\n",
       "   'creationDate': datetime.datetime(2023, 5, 25, 13, 36, 55, 639000, tzinfo=tzlocal())},\n",
       "  {'stateMachineArn': 'arn:aws:states:us-east-1:254224570814:stateMachine:post_scraping',\n",
       "   'name': 'post_scraping',\n",
       "   'type': 'EXPRESS',\n",
       "   'creationDate': datetime.datetime(2023, 5, 25, 10, 12, 8, 607000, tzinfo=tzlocal())}],\n",
       " 'ResponseMetadata': {'RequestId': '50eab3f7-74bf-4fc5-a8f7-ea798ab568b0',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '50eab3f7-74bf-4fc5-a8f7-ea798ab568b0',\n",
       "   'date': 'Thu, 25 May 2023 22:47:51 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '343'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = sfn.list_state_machines()\n",
    "# Get arn for Step Function state machine\n",
    "state_machine_arn = [sm['stateMachineArn'] \n",
    "                     for sm in response2['stateMachines'] \n",
    "                     if sm['name'] == 'comment_scraping'][0]\n",
    "response2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comments table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = 'mysql+mysqlconnector://{}:{}@{}:{}/reddit_scrapes'.format('username',\n",
    "                                                                   'password',\n",
    "                                                                ENDPOINT, PORT)\n",
    "db = dataset.connect(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.util.ResultIter at 0x132af65deb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS comments (\n",
    "        subreddit VARCHAR(255),\n",
    "        post_id VARCHAR(255),\n",
    "        comment_score INTEGER,\n",
    "        comment_body TEXT\n",
    "    )\n",
    "\"\"\"\n",
    "db.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comments', 'posts']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_subreddit(table, subreddit_name):\n",
    "    len_po = len(list(table.find(subreddit=subreddit_name)))\n",
    "    n = len_po // 50\n",
    "    po = table.find(subreddit=subreddit_name)\n",
    "    urls = [entry['url'] for entry in po]\n",
    "    batches = [{'post_url': urls[i:i + n]} for i in range(0, len_po, n)]\n",
    "    # Synchronous Execution\n",
    "    response2 = sfn.start_sync_execution(\n",
    "        stateMachineArn=state_machine_arn,\n",
    "        name='sync_scrape_comment',\n",
    "        input=json.dumps(batches)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subreddit_name in lst_subreddits:\n",
    "    try:\n",
    "        scrape_subreddit(db['posts'], subreddit_name)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20889"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macs30123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
